# S4-E9-Kaggle-Competition-Top_18percent
This repository contains my notebook for the S4-E9 Machine Learning Competition hosted on Kaggle. The notebook showcases my approach to data preprocessing, feature engineering, model selection, and optimization strategies. By utilizing a structured workflow, I achieved a top 18% ranking in the competition. Feel free to explore the code and insights for potential improvements or inspiration for similar competitions!

Competition link : https://www.kaggle.com/competitions/playground-series-s4e9

 ## While working on the notebook I used some of the techniques below:
 * Cross Validation
 * Machine Learning
 * Hyperparameter Optimization (Optuna)
 * Data Preprocessing
 * Pipelines for Machine Learning Algorithms
 * Ensemble Models
 * Combining Models



## Project Evaluation Metric: RMSE

The performance of the models will be assessed using **Root Mean Squared Error (RMSE)** as the primary evaluation metric. RMSE quantifies the average prediction error, providing a clear indication of how closely the modelâ€™s predictions align with actual prices.

$$
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2}
$$

Where:
- **n** = total number of observations  
- **y_i** = actual values  
- **\(\hat{y}_i\)** = predicted values
